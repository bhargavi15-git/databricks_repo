{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0071bfa-2c05-4c0c-8616-77298bb6d4ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "![](https://media.licdn.com/dms/image/v2/D5622AQEQJ3u_ECwEzA/feedshare-shrink_2048_1536/B56Zuz4Cy3HcAk-/0/1768249372070?e=1770249600&v=beta&t=mas2waJIQx2xRTIxJUlK_55097wUCjR1yrL30W_WMZ0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "301ad30e-ff7b-4503-aba3-a850f56bd739",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, TimestampType\n",
    "from pyspark.sql.functions import to_timestamp\n",
    "\n",
    "data_dict = [\n",
    "{\"txn_id\":1,\"vehicle_no\":\"DL01AA1111\",\"vehicle_type\":\"car\",\"crossing_time\":\"2026-01-10 08:00\"},\n",
    "{\"txn_id\":2,\"vehicle_no\":\"DL01AA1111\",\"vehicle_type\":\"car\",\"crossing_time\":\"2026-01-10 11:00\"},\n",
    "{\"txn_id\":3,\"vehicle_no\":\"DL02BB2222\",\"vehicle_type\":\"truck\",\"crossing_time\":\"2026-01-10 09:00\"},\n",
    "{\"txn_id\":4,\"vehicle_no\":\"DL02BB2222\",\"vehicle_type\":\"truck\",\"crossing_time\":\"2026-01-10 16:00\"},\n",
    "{\"txn_id\":5,\"vehicle_no\":\"DL03CC3333\",\"vehicle_type\":\"bus\",\"crossing_time\":\"2026-01-10 10:00\"},\n",
    "{\"txn_id\":6,\"vehicle_no\":\"DL03CC3333\",\"vehicle_type\":\"bus\",\"crossing_time\":\"2026-01-10 12:00\"},\n",
    "{\"txn_id\":7,\"vehicle_no\":\"DL04DD4444\",\"vehicle_type\":\"motorcycle\",\"crossing_time\":\"2026-01-10 11:00\"},\n",
    "{\"txn_id\":8,\"vehicle_no\":\"DL05EE5555\",\"vehicle_type\":\"car\",\"crossing_time\":\"2026-01-10 14:00\"}\n",
    "]\n",
    "schema1 = StructType([\n",
    "    StructField(\"txn_id\", IntegerType(), False),\n",
    "    StructField(\"vehicle_no\", StringType(), False),\n",
    "    StructField(\"vehicle_type\", StringType(), False),\n",
    "    StructField(\"crossing_time\", StringType(), False)\n",
    "])\n",
    "df1 = spark.createDataFrame(data_dict, schema=schema1)\n",
    "df2=df1.withColumn(\"crossing_time\", to_timestamp(\"crossing_time\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66725427-d712-4206-af3b-f99258ce6037",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import lag,timestamp_diff,when, isnull,col,sum\n",
    "df3=df2.withColumn(\"prev_crossing_time\",lag(\"crossing_time\",1).over(Window.partitionBy(\"vehicle_no\").orderBy(\"crossing_time\"))).withColumn(\"time_dff\",timestamp_diff(\"minute\",\"prev_crossing_time\",\"crossing_time\"))\n",
    "df4 = df3.selectExpr(\n",
    "    \"*\",\n",
    "    \"\"\"\n",
    "    CASE\n",
    "        WHEN vehicle_type = 'car'\n",
    "             AND time_dff <= 240 THEN 20\n",
    "        WHEN vehicle_type = 'car'\n",
    "             AND (time_dff > 240 OR time_dff IS NULL) THEN 40\n",
    "\n",
    "        WHEN vehicle_type = 'truck'\n",
    "             AND time_dff <= 240 THEN 40\n",
    "        WHEN vehicle_type = 'truck'\n",
    "             AND (time_dff > 240 OR time_dff IS NULL) THEN 80\n",
    "\n",
    "        WHEN vehicle_type = 'bus'\n",
    "             AND time_dff <= 240 THEN 30\n",
    "        WHEN vehicle_type = 'bus'\n",
    "             AND (time_dff > 240 OR time_dff IS NULL) THEN 70\n",
    "    END AS amount\n",
    "    \"\"\"\n",
    ")\n",
    "display(df4.groupBy().sum(\"amount\"))\n",
    "\n",
    "    \n",
    "display(df4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4989ad52-80a9-4d5d-8a67-346c452137f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Write an SQL query to generate a call summary with the following rules:\n",
    "1. Calls between two persons are bidirectional\n",
    " (10 → 20) and (20 → 10) should be treated as the same pair.\n",
    "2. Always display the smaller person ID as Person1 and the larger person ID as Person2.\n",
    "3. For each unique person pair, calculate:\n",
    " call_count → Total number of calls between the two persons\n",
    " total_duration → Sum of all call durations between the two persons\n",
    "\n",
    "![image_1770741749647.png](./image_1770741749647.png \"image_1770741749647.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "136fd043-62ae-45ed-9dac-620bfe61ac98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE TABLE IF NOT EXISTS input_table (\n",
    "    from_id   INT,\n",
    "    to_id     INT,\n",
    "    duration  INT\n",
    ")\n",
    "USING DELTA;\n",
    "INSERT INTO input_table VALUES\n",
    "(10, 20, 58),\n",
    "(20, 10, 12),\n",
    "(10, 30, 20),\n",
    "(30, 40, 200),\n",
    "(30, 40, 300),\n",
    "(40, 30, 500);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8da8b9df-d383-4374-b8b2-d3b573cca850",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "with temp_tbl as \n",
    "(select  \n",
    "case when from_id > to_id then to_id else from_id \n",
    "end as from_id,\n",
    "case when from_id > to_id then from_id else to_id \n",
    "end as to_id,\n",
    "duration\n",
    "from input_table)\n",
    "select from_id,to_id,sum(duration) from temp_tbl group by from_id,to_id;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "90450ac6-49e7-400c-bce8-0cfeccfbe214",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "![image_1770742413574.png](./image_1770742413574.png \"image_1770742413574.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb7803a7-7b7b-4f3d-a8d2-c88543f3105e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE TABLE IF NOT EXISTS orders_input (\n",
    "    order_id        INT,\n",
    "    customer_id     STRING,\n",
    "    customer_name   STRING,\n",
    "    platform        STRING,\n",
    "    product_stack   STRING,\n",
    "    revenue         INT\n",
    ")\n",
    "USING DELTA;\n",
    "INSERT INTO orders_input VALUES\n",
    "(101, 'C001', 'Alice',   'AWS',   'Data Engineering', 12000),\n",
    "(102, 'C002', 'Bob',     'Azure', 'SQL Analytics',    18000),\n",
    "(103, 'C001', 'Alice',   'AWS',   'Python ETL',        8000),\n",
    "(104, 'C003', 'Charlie', 'GCP',   'BigQuery',         25000),\n",
    "(105, 'C002', 'Bob',     'Azure', 'Power BI',          7000),\n",
    "(106, 'C004', 'Diana',   'AWS',   'Snowflake',        30000),\n",
    "(107, 'C003', 'Charlie', 'GCP',   'Data Pipelines',    5000);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9be8a2c-dc6d-49cb-a18b-91c6d877ab24",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1770742642991}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "with total_rev as \n",
    " (select customer_id,customer_name, sum(revenue) as total_revenue from orders_input group by customer_id,customer_name)\n",
    "\n",
    " select *, rank() over(order by total_revenue desc) as revenue_rank from total_rev;"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "scala",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Linkedin_scenario_1",
   "widgets": {}
  },
  "language_info": {
   "name": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
